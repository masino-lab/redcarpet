{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Munging \n",
    "\n",
    "This notebook contains code for data munging. Specifically, it converts data files generated by R scripts:\n",
    "<br/>001-masinoa-exploratory.rmd\n",
    "<br/>002-masinoa-pc_condition_tree.R\n",
    "<br/>into the ontology and annotations formats necessary for use in the redcarpet rollup codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if not installed, install networkx\n",
    "#!pip install -U networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, csv, time\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# snomed concept files\n",
    "pth = \"./data/rollup/primary_care_only\"\n",
    "files = os.listdir(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on file level_16.csv ...\n",
      "working on file level_08.csv ...\n",
      "working on file level_05.csv ...\n",
      "working on file level_07.csv ...\n",
      "working on file level_09.csv ...\n",
      "working on file level_06.csv ...\n",
      "working on file level_04.csv ...\n",
      "working on file level_12.csv ...\n",
      "working on file level_10.csv ...\n",
      "working on file level_15.csv ...\n",
      "working on file level_01.csv ...\n",
      "working on file level_13.csv ...\n",
      "working on file level_03.csv ...\n",
      "working on file level_11.csv ...\n",
      "working on file level_02.csv ...\n",
      "working on file level_14.csv ...\n"
     ]
    }
   ],
   "source": [
    "# build networkx concept graph from R generated concept ancestor files\n",
    "# the networkx impl will make it easier to check that every concept has a path to\n",
    "# the root concept, clinical finding\n",
    "\n",
    "# code assumes files are structured as \n",
    "# \"concept_id\",\"concept_name\",\"parent_concept_id\",\"parent_concept_name\"\n",
    "#  4274025,\"Disease\",441840,\"Clinical finding\"\n",
    "\n",
    "concept_dict = {}\n",
    "for fn in files:\n",
    "    print(\"working on file {0} ...\".format(fn))\n",
    "    isHeader = True\n",
    "    if fn.endswith('.csv'):\n",
    "        with open('{0}/{1}'.format(pth, fn), 'rt') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                if isHeader:\n",
    "                    isHeader = False\n",
    "                else:\n",
    "                    child_id = int(row[0])\n",
    "                    parent_id = int(row[2])\n",
    "                    if child_id in concept_dict:\n",
    "                        concept_dict[child_id].append(parent_id)\n",
    "                    else:\n",
    "                        concept_dict[child_id] = [parent_id]\n",
    "    \n",
    "g = nx.DiGraph()\n",
    "for child,parents in concept_dict.items():\n",
    "    if child not in g.nodes():\n",
    "        g.add_node(child)\n",
    "    for parent in parents:\n",
    "        if parent not in g:\n",
    "            g.add_node(parent)\n",
    "    \n",
    "for child, parents in concept_dict.items():\n",
    "    for parent in parents:\n",
    "        g.add_edge(child, parent, relation=\"IS_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: found 1 concepts in visits not in ontology\n",
      "[4228490]\n"
     ]
    }
   ],
   "source": [
    "# load conditions file and store in visit dict \n",
    "# expected file format is csv with rows of form\n",
    "# \"person_id\",\"visit_occurrence_id\",\"age_days_visit\",\"visit_start_date\",\"condition_concept_id\"\n",
    "# 4239604,86424890,876,2006-12-11,75860\n",
    "\n",
    "concept_dict = {}\n",
    "missing_concepts = []\n",
    "person_visits = {}\n",
    "with open('./data/pc_conditions_with_visit_meta.csv') as f:\n",
    "    isHeader = True\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if isHeader:\n",
    "            isHeader = False\n",
    "        else:\n",
    "            vid = int(row[1])\n",
    "            cid = int(row[4])\n",
    "            pid = int(row[0])\n",
    "            age_days = int(row[2])\n",
    "            if pid not in person_visits:\n",
    "                person_visits[pid] = []\n",
    "            if vid not in person_visits[pid]:\n",
    "                person_visits[pid].append((vid,age_days))\n",
    "            if cid not in g.nodes():\n",
    "                g.add_node(cid)\n",
    "                missing_concepts.append(cid)\n",
    "            if cid in concept_dict:\n",
    "                concept_dict[cid].append(vid)\n",
    "            else:\n",
    "                concept_dict[cid] = [vid]\n",
    "        \n",
    "print(\"done: found {0} concepts in visits not in ontology\".format(len(missing_concepts)))        \n",
    "print(missing_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 nodes with no path to clinical finding\n"
     ]
    }
   ],
   "source": [
    "# bridge links that do not reach clinical finding \n",
    "# these are the parents of the nodes that \n",
    "# do not have a path up to clinical finding that consist of nodes of only type domain_id=Condition\n",
    "\n",
    "CLINICAL_FINDING = 441840\n",
    "cnt = 0\n",
    "for node in g.nodes():\n",
    "    if node != CLINICAL_FINDING:\n",
    "        # NOTE is_a relation runs in opposite direction of networkx convention\n",
    "        if not nx.has_path(g, node, CLINICAL_FINDING):\n",
    "            g.add_edge(node, CLINICAL_FINDING, relation=\"IS_A\")\n",
    "            cnt += 1\n",
    "print(\"{0} nodes with no path to clinical finding\".format(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# store networkX graph as ontology file for redcarpet project\n",
    "first_line = True\n",
    "with open(\"./data/ontology.txt\", 'a+') as f:\n",
    "    for node in g.nodes():\n",
    "        parents = g[node]\n",
    "        line = \"{0}:\".format(node)\n",
    "        for parent in parents:\n",
    "            line = \"{0}{1},\".format(line, parent)\n",
    "        line = line[:-1]\n",
    "        if first_line:\n",
    "            f.write(line)\n",
    "            first_line = False\n",
    "        else:\n",
    "            line = \"\\n{0}\".format(line)\n",
    "            f.write(line)    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# write visit_dict to annotations file\n",
    "with open('./data/annotations.txt', 'a+') as f:\n",
    "    first_line = True\n",
    "    for cid, vid_list in concept_dict.items():\n",
    "        line = \"{0}:\".format(cid)\n",
    "        for vid in vid_list:\n",
    "            line = \"{0}{1},\".format(line, vid)\n",
    "        line = line[:-1]\n",
    "        if first_line:\n",
    "            f.write(line)\n",
    "            first_line = False\n",
    "        else:\n",
    "            line=\"\\n{0}\".format(line)\n",
    "            f.write(line)\n",
    "print(\"done\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# write person_visit to file\n",
    "with open('./data/person_visits.txt', 'a+') as f:\n",
    "    first_line = True\n",
    "    for pid, vid_list in person_visits.items():\n",
    "        line = \"{0}:\".format(pid)\n",
    "        for tpl in vid_list:\n",
    "            vid = tpl[0]\n",
    "            age = tpl[1]\n",
    "            line = \"{0}{1},{2}:\".format(line, vid,age)\n",
    "        line = line[:-1]\n",
    "        if first_line:\n",
    "            f.write(line)\n",
    "            first_line = False\n",
    "        else:\n",
    "            line=\"\\n{0}\".format(line)\n",
    "            f.write(line)\n",
    "print(\"done\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
